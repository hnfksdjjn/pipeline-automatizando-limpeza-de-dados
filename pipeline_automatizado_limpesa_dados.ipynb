{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKNyq6/HcWo0hHFJMNWEHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnfksdjjn/pipeline-automatizando-limpeza-de-dados/blob/main/pipeline_automatizado_limpesa_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color= red> Pipeline Automatizado Limpeza Dados\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OzcmrrPE6i-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "from IPython.display import display\n",
        "\n",
        "# Configuração do logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# Função 1: Carregar dados\n",
        "def load_data(file_path, delimiter=\";\"):\n",
        "    \"\"\"\n",
        "    Carrega o conjunto de dados a partir de um arquivo CSV.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Caminho para o arquivo CSV.\n",
        "        delimiter (str): Delimitador usado no arquivo CSV (padrão: ';').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame carregado.\n",
        "\n",
        "    Raises:\n",
        "        Exception: Se ocorrer um erro ao carregar os dados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, delimiter=delimiter)\n",
        "        logging.info(\"Dados carregados com sucesso.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao carregar dados: {e}\")\n",
        "        raise\n",
        "\n",
        "# Função 2: Tratar valores ausentes\n",
        "def handle_missing_values(df, strategy=\"mean\"):\n",
        "    \"\"\"\n",
        "    Trata valores ausentes no DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame de entrada.\n",
        "        strategy (str): Estratégia de preenchimento ('mean', 'median', 'mode', 'drop').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com valores ausentes tratados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if strategy == \"mean\":\n",
        "            df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "        elif strategy == \"median\":\n",
        "            df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "        elif strategy == \"mode\":\n",
        "            df.fillna(df.mode().iloc[0], inplace=True)\n",
        "        elif strategy == \"drop\":\n",
        "            df.dropna(inplace=True)\n",
        "        else:\n",
        "            raise ValueError(\"Estratégia inválida. Use 'mean', 'median', 'mode' ou 'drop'.\")\n",
        "        logging.info(f\"Valores ausentes tratados com a estratégia '{strategy}'.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao tratar valores ausentes: {e}\")\n",
        "        raise\n",
        "\n",
        "# Função 3: Remover duplicatas\n",
        "def handle_duplicates(df, subset=None, keep=\"first\"):\n",
        "    \"\"\"\n",
        "    Remove ou ajusta duplicatas no DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame de entrada.\n",
        "        subset (list): Colunas específicas para verificar duplicatas (opcional).\n",
        "        keep (str): Quais duplicatas manter ('first', 'last' ou False).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame sem duplicatas.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        before = len(df)\n",
        "        df.drop_duplicates(subset=subset, keep=keep, inplace=True)\n",
        "        after = len(df)\n",
        "        logging.info(f\"Removidos {before - after} registros duplicados.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao lidar com duplicatas: {e}\")\n",
        "        raise\n",
        "\n",
        "# Função 4: Normalizar colunas numéricas\n",
        "def normalize_columns(df):\n",
        "    \"\"\"\n",
        "    Normaliza valores em todas as colunas numéricas para o intervalo [0, 1].\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame de entrada.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com colunas normalizadas.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
        "        for column in numeric_cols:\n",
        "            df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
        "            logging.info(f\"Coluna '{column}' normalizada.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao normalizar colunas: {e}\")\n",
        "        raise\n",
        "\n",
        "# Função 5: Renomear colunas para melhorar a legibilidade\n",
        "def rename_columns(df, columns_dict):\n",
        "    \"\"\"\n",
        "    Renomeia as colunas para nomes mais legíveis.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame de entrada.\n",
        "        columns_dict (dict): Dicionário com os novos nomes das colunas.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com as colunas renomeadas.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Verifica se todas as colunas no dicionário existem no DataFrame\n",
        "        missing_cols = [col for col in columns_dict if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            logging.warning(f\"As seguintes colunas não foram encontradas e não podem ser renomeadas: {missing_cols}\")\n",
        "\n",
        "        # Renomeia as colunas que existem no DataFrame\n",
        "        df.rename(columns={col: columns_dict[col] for col in columns_dict if col in df.columns}, inplace=True)\n",
        "        logging.info(\"Colunas renomeadas com sucesso.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao renomear as colunas: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Função 6: Formatar os dados para facilitar a leitura\n",
        "def format_data(df):\n",
        "    \"\"\"\n",
        "    Melhora a formatação dos dados para torná-los mais legíveis e fáceis de interpretar.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame de entrada.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com formatação melhorada.\n",
        "    \"\"\"\n",
        "    # Arredondar as colunas numéricas para 2 casas decimais\n",
        "    df = df.round(2)\n",
        "\n",
        "    # Converte as colunas 'Masculino' e 'Feminino' para formatos mais legíveis\n",
        "    df['Sexo'] = df['Sexo'].replace({'M': 'Masculino', 'F': 'Feminino'})\n",
        "\n",
        "    # Formatar valores como porcentagem (multiplicar por 100)\n",
        "    percent_columns = ['x6', 'x7', 'x8', 'x9', 'x10', 'x11']\n",
        "    for col in percent_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col] * 100  # Multiplicando por 100 para mostrar em porcentagem\n",
        "            df[col] = df[col].apply(lambda x: f\"{x:.2f}%\")  # Formatando como percentual\n",
        "\n",
        "    logging.info(\"Dados formatados com sucesso.\")\n",
        "    return df\n",
        "\n",
        "# Função para exibir os dados de forma mais legível\n",
        "def display_formatted_data(df):\n",
        "    \"\"\"\n",
        "    Exibe o DataFrame de forma mais legível.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame a ser exibido.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    display(df.head())\n",
        "\n",
        "# Função para salvar os dados\n",
        "def save_data(df, output_path):\n",
        "    \"\"\"\n",
        "    Salva o DataFrame em um arquivo CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame a ser salvo.\n",
        "        output_path (str): Caminho do arquivo para salvar os dados.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(output_path, index=False)\n",
        "        logging.info(f\"Dados salvos com sucesso no arquivo {output_path}.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao salvar os dados: {e}\")\n",
        "        raise\n",
        "\n",
        "# Pipeline principal para carregar e formatar os dados\n",
        "def main_pipeline(file_path, output_path):\n",
        "    \"\"\"\n",
        "    Executa o pipeline completo de carregamento e formatação dos dados.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Caminho para o arquivo CSV de entrada.\n",
        "        output_path (str): Caminho para salvar o arquivo CSV limpo.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame formatado.\n",
        "    \"\"\"\n",
        "    # Carregar dados\n",
        "    df = load_data(file_path)\n",
        "\n",
        "    # Tratar valores ausentes\n",
        "    df = handle_missing_values(df)\n",
        "\n",
        "    # Remover duplicatas\n",
        "    df = handle_duplicates(df)\n",
        "\n",
        "    # Normalizar colunas numéricas\n",
        "    df = normalize_columns(df)\n",
        "\n",
        "    # Renomear colunas\n",
        "    columns_dict = {\n",
        "        'X1': 'ID', 'X2': 'Idade', 'X3': 'Sexo', 'X4': 'Estado',\n",
        "        'X4.1': 'Renda', 'X6': 'Gasto1', 'X7': 'Gasto2', 'X8': 'Gasto3',\n",
        "        'X9': 'Gasto4', 'X10': 'Gasto5', 'X11': 'Gasto6'\n",
        "    }\n",
        "    df = rename_columns(df, columns_dict)\n",
        "\n",
        "    # Melhorar a formatação dos dados\n",
        "    df = format_data(df)\n",
        "\n",
        "    # Exibir dados formatados\n",
        "    display_formatted_data(df)\n",
        "\n",
        "    # Salvar os dados limpos\n",
        "    save_data(df, output_path)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Executar o pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"dados.csv\"  # Substitua pelo caminho do seu arquivo CSV\n",
        "    output_path = \"dados_limpos.csv\"  # Caminho para salvar o arquivo limpo\n",
        "    main_pipeline(file_path, output_path)\n"
      ],
      "metadata": {
        "id": "MtP3jK7VBleZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}